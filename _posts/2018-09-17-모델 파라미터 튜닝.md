---
layout: post
title: "파라미터튜닝을 도전해보자"
subtitle: "테라비이트의 텍스트 문서를 분석하는 방법"
author: "SeungHeon Doh"
header-img: "img/post-bg-halting.jpg"
header-mask: 0.3
tags:
  - LDA
  - Gensim
  - 토픽모델링
---
 The Space of Topic Coherence Measures
> 2015년에 출간된 https://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf 을 참고하였습니다.

## 파라미터 튜닝이 필요한 이유

어떻게 문서들 집합간의 일관성을 정량화 할 것인가? 문서 집합의 Coherence 가 높아지면 monotonic 해지는 문제점이 생긴다. 하지만 다른 사실을 추가한다면 
단조로움이 보다 감소되는 경향이 있다. 이 것은 마치 Bias-Variance tradeoff 처럼, 만약 특정 coherence가 너무 높아지면 정보의 양이 줄어들게 되고, 
coherence가 너무 낮아 정보들이 인관성이 없다면, 분석의 의미가 낲아지게 됩니다. 그렇다면 어떻게 해야 좋은 LDA모델이 나오게 될까요?


### Distinctiveness (구별성?)
얼마나 많은 단어가, Topics들에 공유가 되는지를 뜻합니다. 구별성이 높을수록 적은 Topic에 단어가 포합됩니다.
<br>
$
\mathcal{D}(w)
= \sum_{k}
p\left(k|w\right) \log \frac{p(k|w)}{p(k)}
= \text{KL}\big(p(k|w) \ \Vert \ p(k)\big)
$

### Saliency (돌출성?)

단어 w가 그의 Distinctiveness에 빈도에 가중치를 받은 것입니다. 빈도 p(w)에 관한 순위를 비교하여, 높은 빈도의 순위에 Distinctivenss 의 패널티를 줍니다. 따라서 하나의 주제를 대표할 좋은 단어를 찾아내는 지표로 사용됩니다.

$
\mathcal{S}(w) = p(w) \mathcal{D}(w)
$

### Pointwise mutual information(PMI)
$n$이 특정 단어가 여러 문서에서 등장한 갯수이고, $D$가 전체 문서의 수라고 할때,
<br>
$
\text{PMI}(w_i, w_j) = \log \frac{\frac n D}{\frac n D \cdot \frac n D} = \log D - \log n
$
<br>
${w_i, w_j}$의 PMI는 전체 문서의 log - 동시 등장한 단어가 발생한 문서의 갯수의 log로 정의할 수 있다. 이 PMI가 극대화 되는 지점은 전체 단어가 모든 문서에서 동시 등장한 경우이다. 이러한 PMI는 적은 빈도의 단어를 과다 추정하는 경향이 있다. __즉 PMI가 높다는 것은, 낮은 빈도의 단어를 찾는것 이라고 할수 있습니다.__

### Perplexity, Topic Coherence의 차이 비교

1. Perplexity
    - 의미 의미확률 모델이 결과를 얼마나 정확하게 예측하는지.낮을수록 정확하게 예측. 
    - 토픽 모델링 기법이 얼마나 빠르게 수렴하는지 확인할 때,
    - 확률 모델이 다른 모델에 비해 얼마나 개선되었는지 평가할 때,
    - 동일 모델 내 파라미터에 따른 성능 평가할 때 주로 사용 
    - 한계Perplexity가 낮다고 해서, 결과가 해석 용이하다는 의미가 아님

<br>
2. Coherence
    - 토픽이 얼마나 의미론적으로 일관성 있는지. 
    - 높을수록 의미론적 일관성 높음
    - 해당 모델이 얼마나 실제로 의미있는 결과를 내는지 확인하기 위해 사용
    - 평가를 진행하기 위해 다른 외부 데이터(코퍼스, 시소러스 등)가 필요

출처: http://bab2min.tistory.com/587?category=673750 [나의 큰 O는 logx야..]

### Coherence 모델을 평가해보자

- 일관성을 사용하여 LDA모델을 평가해봅시다. 일관성은 주제가 사람에게 어떻게 해석 될 수 있는지를 나타내는 척도입니다. 
- LDA에 대한 Topic-Term 행렬이 주어지면, 가장 높은 용어에서 가장 낮은 용어 가중치로 각 주제를 정렬한 다음, 처음 N개의 용어를 선택합니다.

- 일관성은 근본적으로 이 단어들이 얼마나 유사한지를 측정합니다.

- c_v 일관성은 코퍼스에 expensive pass를 만들어서 각 주제의 상위 N용어 목록에 있는 용어에 대한 계수만 누적합니다.

```py
texts = [['human', 'interface', 'computer'],
         ['survey', 'user', 'computer', 'system', 'response', 'time'],
         ['eps', 'user', 'interface', 'system'],
         ['system', 'human', 'system', 'eps'],
         ['user', 'response', 'time'],
         ['trees'],
         ['graph', 'trees'],
         ['graph', 'minors', 'trees'],
         ['graph', 'minors', 'survey']]

cm = models.CoherenceModel.for_models(
    trained_models.values(), dictionary, texts=texts, coherence='c_v')
    

coherence_estimates = cm.compare_models(trained_models.values())
coherences = dict(zip(trained_models.keys(), coherence_estimates))

def print_coherence_rankings(coherences):
    avg_coherence = \
        [(num_topics, avg_coherence)
         for num_topics, (_, avg_coherence) in coherences.items()]
    ranked = sorted(avg_coherence, key=lambda tup: tup[1], reverse=True)
    print("Ranked by average '%s' coherence:\n" % cm.coherence)
    for item in ranked:
        print("num_topics=%d:\t%.4f" % item)
    print("\nBest: %d" % ranked[0][0])
    
print_coherence_rankings(coherences)
```